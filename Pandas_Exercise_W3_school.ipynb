{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjnUb/tE6aWzBVyT5kuKl2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKASHPATI007/Pandas-exercise-w3school/blob/main/Pandas_Exercise_W3_school.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5HgsGJuO4X5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pandas Series**"
      ],
      "metadata": {
        "id": "6xuxkn6IP8_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-1.** Write a Pandas program to create and display a one-dimensional array-like object containing an array of data using Pandas module.\n",
        "\n",
        "**Ans-** **pd.Series([2, 4, 6, 8, 10])**\n",
        "\n",
        "**Ques:-2.** Write a Pandas program to convert a Panda module Series to Python list and it's type.\n",
        "\n",
        "**Ans:- ds = pd.Series([2, 4, 6, 8, 10])--->ds.tolist()**\n",
        "\n",
        "**Ques:-3.** Write a Pandas program to add, subtract, multiple and divide two Pandas Series.\n",
        "\n",
        "**Ans:- ds1 = pd.Series([2, 4, 6, 8, 10] and ds2 = pd.Series([1, 3, 5, 7, 9])---> add- ds1+ds2---> sub- ds1-ds2 ---> mult- ds1*ds2 ---> div- ds1/ds2**\n",
        "\n",
        "**Ques:-4.** Write a Pandas program to compare the elements of the two Pandas Series.\n",
        "\n",
        "**Ans:- ds1 = pd.Series([2, 4, 6, 8, 10] and ds2 = pd.Series([1, 3, 5, 7, 9])--->equal- ds1 == ds2---> greater- ds1>ds2**\n",
        "\n",
        "**Ques:-5.** Write a Pandas program to convert a dictionary to a Pandas series.\n",
        "\n",
        "**Ans:- d1 = {'a': 100, 'b': 200, 'c':300, 'd':400, 'e':800}--->new_series = pd.Series(d1)**\n",
        "\n",
        "**Ques:-6.** Write a Pandas program to convert a NumPy array to a Pandas series.\n",
        "\n",
        "**Ans:- np_array = np.array([10, 20, 30, 40, 50])--->new_series = pd.Series(np_array)**\n",
        "\n",
        "**Ques:-7.** Write a Pandas program to change the data type of given a column or a Series.\n",
        "\n",
        "**Ans:- s1 = pd.Series(['100', '200', 'python', '300.12', '400'])---> s2 = pd.to_numeric(s1, errors='coerce')**\n",
        "\n",
        "**Ques:-8.** Write a Pandas program to convert the first column of a DataFrame as a Series.\n",
        "\n",
        "**Ans:- df.ix[:,0]**\n",
        "\n",
        "**Ques:-9.** Write a Pandas program to convert a given Series to an array.\n",
        "\n",
        "**Ans:- s1 = pd.Series(['100', '200', 'python', '300.12', '400'])--->Series_to_array-> a = s1.values**\n",
        "\n",
        "**Ques:-10.** Write a Pandas program to sort a given Series.\n",
        "\n",
        "**Ans:-  s = pd.Series(['100', '200', 'python', '300.12', '400'])---> new_s = pd.Series(s).sort_values()**\n",
        "\n",
        "**Ques:-11.** Write a Pandas program to convert Series of lists to one Series.\n",
        "\n",
        "**Ans:- s = pd.Series([['Red', 'Green', 'White'],['Red', 'Black']['Yellow']])---> s = s.apply(pd.Series).stack().reset_index(drop=True)**\n",
        "\n",
        "**Ques:-12.** Write a Pandas program to add some data to an existing Series.\n",
        "\n",
        "**Ans:- s = pd.Series(['100', '200', 'python', '300.12', '400'])---> new_s = pd.concat([s, pd.Series([500, \"php\"])], ignore_index=True)**\n",
        "\n",
        "**Ques:-13.** Write a Pandas program to create a subset of a given series based on value and condition.\n",
        "\n",
        "**Ans:- s = pd.Series([0,1,2,3,4,5,6,7,8,9,10])---> n = 6--->new_s = s[s < n]**\n",
        "\n",
        "**Ques:-14.** Write a Pandas program to change the order of index of a given series.\n",
        "\n",
        "**Ans:- s = pd.Series(data = [1,2,3,4,5], index = ['A', 'B', 'C','D','E'])--->After changing order---> s = s.reindex(index = ['B','A','C','D','E'])**\n",
        "\n",
        "**Ques:-15.** Write a Pandas program to create the mean and standard deviation of the data of a given Series.\n",
        "\n",
        "**Ans:- s = pd.Series(data = [1,2,3,4,5,6,7,8,9,5,3])--->s.mean()--->s.std()**\n",
        "\n",
        "**Ques:-16.** Write a Pandas program to get the items of a given series not present in another given series.\n",
        "\n",
        "**Ans:- sr1 = pd.Series([1, 2, 3, 4, 5]),sr2 = pd.Series([2, 4, 6, 8, 10])---> result = sr1[~sr1.isin(sr2)]**\n",
        "\n",
        "**Ques:-17.** Write a Pandas program to get the items which are not common of two given series.\n",
        "\n",
        "**Ans:- sr1 = pd.Series([1, 2, 3, 4, 5]),sr2 = pd.Series([2, 4, 6, 8, 10])--->sr11 = pd.Series(np.union1d(sr1, sr2)),sr22 = pd.Series(np.intersect1d(sr1, sr2))---->result = sr11[~sr11.isin(sr22)]**\n",
        "\n",
        "**Ques:-18.** Write a Pandas program to compute the minimum, 25th percentile, median, 75th, and maximum of a given series.\n",
        "\n",
        "**Ans:- num_state = np.random.RandomState(100)--->num_series = pd.Series(num_state.normal(10, 4, 20))---> result = np.percentile(num_series, q=[0, 25, 50, 75, 100])**\n",
        "\n",
        "**Ques:-19.** Write a Pandas program to calculate the frequency counts of each unique value of a given series.\n",
        "\n",
        "**Ans:- num_series = pd.Series(np.take(list('0123456789'), np.random.randint(10, size=40)))---> result = num_series.value_counts()**\n",
        "\n",
        "**Ques:-20.** Write a Pandas program to display most frequent value in a given series and replace everything else as 'Other' in the series.\n",
        "\n",
        "**Ans:- num_series = pd.Series(np.random.randint(1, 5, [15]))--->num_series.value_counts()---> result = num_series[~num_series.isin(num_series.value_counts().index[:1])] = 'Other'**\n",
        "\n",
        "**Ques:-21.** Write a Pandas program to find the positions of numbers that are multiples of 5 of a given series.\n",
        "\n",
        "**Ans:- num_series = pd.Series(np.random.randint(1, 10, 9))--->result = np.where(num_series % 5==0)**\n",
        "\n",
        "**Ques:-22.** Write a Pandas program to extract items at given positions of a given series.\n",
        "\n",
        "**Ans:-num_series = pd.Series(list('2390238923902390239023'))--->element_pos = [0, 2, 6, 11, 21]--->result = num_series.take(element_pos)**\n",
        "\n",
        "**Ques:-23.** Write a Pandas program to get the positions of items of a given series in another given series.\n",
        "\n",
        "**Ans:- series1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])--->series2 = pd.Series([1, 3, 5, 7, 10])---> result = [pd.Index(series1).get_loc(i) for i in series2]**\n",
        "\n",
        "**Ques:-24.** Write a Pandas program convert the first and last character of each word to upper case in each word of a given series.\n",
        "\n",
        "**Ans:- series1 = pd.Series(['php', 'python', 'java', 'c#'])---> result = series1.map(lambda x: x[0].upper() + x[1:-1] + x[-1].upper())**\n",
        "\n",
        "**Ques:-25.** Write a Pandas program to calculate the number of characters in each word in a given series.\n",
        "\n",
        "**Ans:- series1 = pd.Series(['Php', 'Python', 'Java', 'C#'])---> result = series1.map(lambda x: len(x))**\n",
        "\n",
        "**Ques:-26.** Write a Pandas program to compute difference of differences between consecutive numbers of a given series.\n",
        "\n",
        "**Ans:- series1 = pd.Series([1, 3, 5, 8, 10, 11, 15])---> series1.diff().tolist()---> series1.diff().diff().tolist()**\n",
        "\n",
        "**Ques:-27.** Write a Pandas program to convert a series of date strings to a timeseries.\n",
        "\n",
        "**Ans:- date_series = pd.Series(['01 Jan 2015', '10-02-2016', '20180307', '2014/05/06', '2016-04-12', '2019-04-06T11:20'])----> pd.to_datetime(date_series)**\n",
        "\n",
        "**Ques:-28.** Write a Pandas program to get the day of month, day of year, week number and day of week from a given series of date strings.\n",
        "\n",
        "**Ans:- from dateutil.parser import parse--->date_series = pd.Series(['01 Jan 2015', '10-02-2016', '20180307', '2014/05/06', '2016-04-12', '2019-04-06T11:20'])----> date_series = date_series.map(lambda x: parse(x))----> month-> date_series.dt.day.tolist()---> year-> date_series.dt.dayofyear.tolist()---> week-> date_series.dt.weekofyear.tolist()---> Day_of_week-> date_series.dt.weekday_name.tolist()**\n",
        "\n",
        "**Ques:-29.** Write a Pandas program to convert year-month string to dates adding a specified day of the month.\n",
        "\n",
        "**Ans:-from dateutil.parser import parse--->date_series = pd.Series(['Jan 2015', 'Feb 2016', 'Mar 2017', 'Apr 2018', 'May 2019'])---> result = date_series.map(lambda d: parse('11 ' + d))**\n",
        "\n",
        "**Ques:-30.** Write a Pandas program to filter words from a given series that contain atleast two vowels\n",
        "\n",
        "**Ans:- from collections import Counter---> color_series = pd.Series(['Red', 'Green', 'Orange', 'Pink', 'Yellow', 'White'])---> result =color_series.map(lambda c: sum([Counter(c.lower()).get(i, 0) for i in list('aeiou')]) >= 2)**\n",
        "\n",
        "**Ques:-31** Write a Pandas program to compute the Euclidean distance between two given series.\n",
        "Euclidean distance\n",
        "\n",
        "**Ans:- x = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])---> y = pd.Series([11, 8, 7, 5, 6, 5, 3, 4, 7, 1])----> np.linalg.norm(x-y)**\n",
        "\n",
        "**Ques:-32.** Write a Pandas program to find the positions of the values neighboured by smaller values on both sides in a given series.\n",
        "\n",
        "**Ans:- nums = pd.Series([1, 8, 7, 5, 6, 5, 3, 4, 7, 1])---> temp = np.diff(np.sign(np.diff(nums)))---> result = np.where(temp == -2)[0] + 1**\n",
        "\n",
        "**Ques:-33** Write a Pandas program to replace missing white spaces in a given string with the least frequent character.\n",
        "\n",
        "**Ans:- str1 = 'abc def abcdef icd'--->ser = pd.Series(list(str1))--->\n",
        "element_freq = ser.value_counts()--->current_freq = element_freq.dropna().index[-1]----> result = \"\".join(ser.replace(' ', current_freq))**\n",
        "\n",
        "**Ques:-34.** Write a Pandas program to compute the autocorrelations of a given numeric series.\n",
        "\n",
        "**Ans:- num_series = pd.Series(np.arange(15) + np.random.normal(1, 10, 15))---> autocorrelations = [num_series.autocorr(i).round(2) for i in range(11)]---> autocorrelations[1:]**\n",
        "\n",
        "**Ques:-35.** Write a Pandas program to create a TimeSeries to display all the Sundays of given year.\n",
        "\n",
        "**Ans:- result = pd.Series(pd.date_range('2020-01-01', periods=52, freq='W-SUN'))**\n",
        "\n",
        "**Ques:-36.** Write a Pandas program to convert given series into a dataframe with its index as another column on the dataframe.\n",
        "\n",
        "**Ans:- char_list = list('ABCDEFGHIJKLMNOP')--->num_arra = np.arange(8)--->num_dict = dict(zip(char_list, num_arra))--->num_ser = pd.Series(num_dict)---> df = num_ser.to_frame().reset_index()**\n",
        "\n",
        "**Ques:-37.** Write a Pandas program to stack two given series vertically and horizontally.\n",
        "\n",
        "**Ans:- series1 = pd.Series(range(10))--->series2 = pd.Series(list('pqrstuvwxy'))---> series1.append(series2)---->df = pd.concat([series1, series2], axis=1)**\n",
        "\n",
        "**Ques:-38.** Write a Pandas program to check the equality of two given series.\n",
        "\n",
        "**Ans:- nums1 = pd.Series([1, 8, 7, 5, 6, 5, 3, 4, 7, 1])--->nums2 = pd.Series([1, 8, 7, 5, 6, 5, 3, 4, 7, 1])--->nums1 == nums2**\n",
        "\n",
        "**Ques:-39.** Write a Pandas program to find the index of the first occurrence of the smallest and largest value of a given series.\n",
        "\n",
        "**Ans:- nums = pd.Series([1, 3, 7, 12, 88, 23, 3, 1, 9, 0])---> nums.idxmin()---> nums.idxmax()**\n",
        "\n",
        "**Ques:- 40.** Write a Pandas program to check inequality over the index axis of a given dataframe and a given series.\n",
        "\n",
        "**Ans:- df_data = pd.DataFrame({'W':[68,75,86,80,None],'X':[78,75,None,80,86], 'Y':[84,94,89,86,86],'Z':[86,97,96,72,83]});\n",
        "sr_data = pd.Series([68, 75, 86, 80, None]) ----> df_data.ne(sr_data, axis = 0)**\n"
      ],
      "metadata": {
        "id": "fFyWMQSxOuu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PANDAS DATAFRAME**"
      ],
      "metadata": {
        "id": "mnRBP5fD_xT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
        "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
        "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
        "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
        "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
        "\n",
        "df = pd.DataFrame(exam_data , index=labels)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "9K6cBosX4Om2",
        "outputId": "c0181206-9129-4d77-d57a-217de8073dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        name  score  attempts qualify\n",
              "a  Anastasia   12.5         1     yes\n",
              "b       Dima    9.0         3      no\n",
              "c  Katherine   16.5         2     yes\n",
              "d      James    NaN         3      no\n",
              "e      Emily    9.0         2      no\n",
              "f    Michael   20.0         3     yes\n",
              "g    Matthew   14.5         1     yes\n",
              "h      Laura    NaN         1      no\n",
              "i      Kevin    8.0         2      no\n",
              "j      Jonas   19.0         1     yes"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfb53004-f1cd-4754-8885-6b8cefc862ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>attempts</th>\n",
              "      <th>qualify</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>Anastasia</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b</th>\n",
              "      <td>Dima</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c</th>\n",
              "      <td>Katherine</td>\n",
              "      <td>16.5</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d</th>\n",
              "      <td>James</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e</th>\n",
              "      <td>Emily</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f</th>\n",
              "      <td>Michael</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>Matthew</td>\n",
              "      <td>14.5</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h</th>\n",
              "      <td>Laura</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>Kevin</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>j</th>\n",
              "      <td>Jonas</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfb53004-f1cd-4754-8885-6b8cefc862ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfb53004-f1cd-4754-8885-6b8cefc862ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfb53004-f1cd-4754-8885-6b8cefc862ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-1.** Write a Pandas program to create a dataframe from a dictionary and display it.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]})**\n",
        "\n",
        "**Ques:-2.** Write a Pandas program to create and display a DataFrame from a specified dictionary data which has the index labels.\n",
        "\n",
        "**Ans:- exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James','Rajesh'],'score': [12.5, 9, 16.5, np.nan, 9],'attempts': [1, 3, 2, 3, 2],'qualify': ['yes', 'no', 'yes', 'no', 'no']}--->labels = ['a', 'b', 'c', 'd', 'e']--->df = pd.DataFrame(exam_data , index=labels)**\n",
        "\n",
        "**Ques:-3.** Write a Pandas program to display a summary of the basic information about a specified DataFrame and its data.\n",
        "\n",
        "**Ans:- df.info()**\n",
        "\n",
        "**Ques:-4.** Write a Pandas program to get the first 3 rows of a given DataFrame.\n",
        "\n",
        "**Ans:- df.iloc[:3]**\n",
        "\n",
        "**Ques:-5.** Write a Pandas program to select the 'name' and 'score' columns from the following DataFrame.\n",
        "\n",
        "**Ans:- df[['name', 'score']]**\n",
        "\n",
        "**Ques:-6.** Write a Pandas program to select the specified columns and rows from a given data frame.\n",
        "\n",
        "**Ans:- df.iloc[[1, 3, 5, 6], [1, 3]]**--->give (1,2,5,6-rows & 1,3-columns)\n",
        "\n",
        "**Ques:-7.** Write a Pandas program to select the rows where the number of attempts in the examination is greater than 2.\n",
        "\n",
        "**Ans:- df[df['attempts'] > 2]**\n",
        "\n",
        "**Ques:-8.** Write a Pandas program to count the number of rows and columns of a DataFrame.\n",
        "\n",
        "**Ans:- total_rows=len(df.axes[0])--->total_cols=len(df.axes[1])**\n",
        "\n",
        "**Ques:-9.** Write a Pandas program to select the rows where the score is missing, i.e. is NaN.\n",
        "\n",
        "**Ans:- df[df['score'].isnull()]**\n",
        "\n",
        "**Ques:-10.** Write a Pandas program to select the rows the score is between 15 and 20 (inclusive).\n",
        "\n",
        "**Ans:- df[df['score'].between(15, 20)]**\n",
        "\n",
        "**Ques:-11.** Write a Pandas program to select the rows where number of attempts in the examination is less than 2 and score greater than 15.\n",
        "\n",
        "**Ans:- df[(df['attempts'] < 2) & (df['score'] > 15)]**\n",
        "\n",
        "**Ques:-12.** Write a Pandas program to change the score in row 'd' to 11.5.\n",
        "\n",
        "**Ans:- df.loc['d', 'score'] = 11.5**\n",
        "\n",
        "**Ques:-13.** Write a Pandas program to calculate the sum of the examination attempts by the students.\n",
        "\n",
        "**Ans:- df['attempts'].sum()**\n",
        "\n",
        "**Ques:-14.** Write a Pandas program to calculate the mean of all students' scores. Data is stored in a dataframe.\n",
        "\n",
        "**Ans:- df['score'].mean()**\n",
        "\n",
        "**Ques:-15.** Write a Pandas program to append a new row 'k' to data frame with given values for each column. Now delete the new row and return the original DataFrame.\n",
        "\n",
        "**Ans:- Append- df.loc['k'] = [1, 'Suresh', 'yes', 15.5]--->Delete new row- df.drop('k')**\n",
        "\n",
        "**Ques:-16.** Write a Pandas program to sort the DataFrame first by 'name' in descending order, then by 'score' in ascending order.\n",
        "\n",
        "**Ans:- df.sort_values(by=['name', 'score'], ascending=[False, True])**\n",
        "\n",
        "**Ques:-17.** Write a Pandas program to replace the 'qualify' column contains the values 'yes' and 'no' with True and False.\n",
        "\n",
        "**Ans:- df['qualify'] = df['qualify'].map({'yes': True, 'no': False})**\n",
        "\n",
        "**Ques:-18.** Write a Pandas program to change the name 'James' to 'Suresh' in name column of the DataFrame.\n",
        "\n",
        "**Ans:- df['name'] = df['name'].replace('James', 'Suresh')**\n",
        "\n",
        "**Ques:-19.** Write a Pandas program to delete the 'attempts' column from the DataFrame.\n",
        "\n",
        "**Ans:- df.pop('attempts')**\n",
        "\n",
        "**Ques:-20.** Write a Pandas program to insert a new column in existing DataFrame.\n",
        "\n",
        "**Ans:- color = ['Red','Blue','Orange','Red','White','White','Blue','Green','Green','Red']--->df['color'] = color**--->Added new column color to df\n",
        "\n",
        "**Ques:-21.** Write a Pandas program to iterate over rows in a DataFrame.\n",
        "\n",
        "**Ans:- exam_data = [{'name':'Anastasia', 'score':12.5}, {'name':'Dima','score':9}, {'name':'Katherine','score':16.5}]--->df = pd.DataFrame(exam_data)--->for index, row in df.iterrows():--->print(row['name'], row['score'])**\n",
        "\n",
        "**Ques:-22.** Write a Pandas program to get list from DataFrame column headers.\n",
        "\n",
        "**Ans:- list(df.columns.values)**\n",
        "\n",
        "**Ques:-23.** Write a Pandas program to rename columns of a given DataFrame\n",
        "\n",
        "**ans:- df = df.rename(columns={'col1': 'Column1', 'col2': 'Column2', 'col3': 'Column3'})**\n",
        "\n",
        "**Ques:-24.** Write a Pandas program to select rows from a given DataFrame based on values in some columns.\n",
        "\n",
        "**Ans:- d = {'col1': [1, 4, 3, 4, 5], 'col2': [4, 5, 6, 7, 8], 'col3': [7, 8, 9, 0, 1]}--->df = pd.DataFrame(data=d)---> df.loc[df['col1'] == 4]**\n",
        "\n",
        "**Ques:-25.** Write a Pandas program to change the order of a DataFrame columns.\n",
        "\n",
        "**Ans:- After altering col1 and col3----->df = df[['col3', 'col2', 'col1']]**\n",
        "\n",
        "**Ques:-26.** Write a Pandas program to add one row in an existing DataFrame.\n",
        "\n",
        "**Ans:- d = {'col1': [1, 4, 3, 4, 5], 'col2': [4, 5, 6, 7, 8], 'col3': [7, 8, 9, 0, 1]}--->df = pd.DataFrame(data=d)df2 = {'col1': 10, 'col2': 11, 'col3': 12}---->df = df.append(df2, ignore_index=True)**\n",
        "\n",
        "**Ques:-27.** Write a Pandas program to write a DataFrame to CSV file using tab separator.\n",
        "\n",
        "**Ans:- d = {'col1': [1, 4, 3, 4, 5], 'col2': [4, 5, 6, 7, 8], 'col3': [7, 8, 9, 0, 1]}--->df = pd.DataFrame(data=d)--->df.to_csv('new_file.csv', sep='\\t', index=False)--->new_df = pd.read_csv('new_file.csv')**\n",
        "\n",
        "**Ques:-28.** Write a Pandas program to count city wise number of people from a given of data set (city, name of the person).\n",
        "\n",
        "**Ans:- df1 = pd.DataFrame({'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
        "'city': ['California', 'Los Angeles', 'California', 'California', 'California', 'Los Angeles', 'Los Angeles', 'Georgia', 'Georgia', 'Los Angeles']})---->g1 = df1.groupby([\"city\"]).size().reset_index(name='Number of people')**\n",
        "\n",
        "**Ques:-29.** Write a Pandas program to delete DataFrame row(s) based on given column value.\n",
        "\n",
        "**Ans:- df = df[df.col2 != 5]** - delete 2nd row as it contain 5 in column2\n",
        "\n",
        "**Ques:-30.** Write a Pandas program to widen output display to see more columns.\n",
        "\n",
        "**Ans:- pd.set_option('display.max_rows', 500) -sets the maximum number of rows that Pandas will display to 500.---->pd.set_option('display.max_columns', 500)- sets the maximum number of columns that Pandas will display to 500.---->pd.set_option('display.width', 1000) -sets the maximum width of the display to 1000 characters.**\n",
        "\n",
        "**Ques:-31.** Write a Pandas program to select a row of series/dataframe by given integer index.\n",
        "\n",
        "**Ans:- result = df.iloc[[2]]**-give third row of dataframe as index 2\n",
        "\n",
        "**Ques:-32.** Write a Pandas program to replace all the NaN values with Zero's in a column of a dataframe.\n",
        "\n",
        "**Ans:- df =  df.fillna(0)**\n",
        "\n",
        "**Ques:-33.** Write a Pandas program to convert index in a column of the given dataframe.\n",
        "\n",
        "**Ans:-** After converting index in a column---->**df.reset_index(level=0, inplace=True)**--->Hiding index---> **df.to_string(index=False)**\n",
        "\n",
        "**Ques:-34.** Write a Pandas program to set a given value for particular cell in  DataFrame using index value.\n",
        "\n",
        "**Ans:- df.set_value(8, 'score', 10.2)**---> The set_value() function is used to modify the value of the cell in the 8th row and 'score' column to 10.2.\n",
        "\n",
        "**Ques:-35.** Write a Pandas program to count the NaN values in one or more columns in DataFrame.\n",
        "\n",
        "**Ans:- df.isnull().values.sum()**\n",
        "\n",
        "**Ques:-36.** Write a Pandas program to drop a list of rows from a specified DataFrame.\n",
        "\n",
        "**Ans:- df = df.drop(df.index[[2,4]])**--->removed 2nd & 4th rows\n",
        "\n",
        "**Ques:-37.** Write a Pandas program to reset index in a given DataFrame.\n",
        "\n",
        "**Ans:- df = df.drop([0, 1])**--> This code drops the rows with index 0 and 1 **df = df.reset_index()**---> This code resets the index using the reset_index() method, which creates a new column called \"index\" with the index values before resetting.\n",
        "\n",
        "**Ques:-38.** Write a Pandas program to divide a DataFrame in a given ratio.\n",
        "\n",
        "**Ans:- df = pd.DataFrame(np.random.randn(10, 2))--->part_70 = df.sample(frac=0.7,random_state=10)--->part_30 = df.drop(part_70.index)**---> creates a new DataFrame 'part_70' by sampling 70% of the rows from 'df' using the sample method. The 'frac' parameter specifies the fraction of the rows to be sampled, while the random_state parameter is used to ensure that the same set of rows is always sampled if the code is run again with the same random_state value.\n",
        "\n",
        "**Ques:-39.** Write a Pandas program to combining two series into a DataFrame.\n",
        "\n",
        "**Ans:- s1 = pd.Series(['100', '200', 'python', '300.12', '400'])--->s2 = pd.Series(['10', '20', 'php', '30.12', '40'])--->df = pd.concat([s1, s2], axis=1)**---> resulting DataFrame will have 5 rows and 2 columns.\n",
        "\n",
        "**Ques:-40.** Write a Pandas program to shuffle a given DataFrame rows.\n",
        "\n",
        "**Ans:- df = df.sample(frac=1)**--->sample method is used to shuffle the rows of this DataFrame in a random order--->frac=0.5 so half rows. frac=2 so double rows means earlier 4 then this time will 8.\n",
        "\n",
        "**Ques:-41.** Write a Pandas program to convert DataFrame column type from string to datetime.\n",
        "\n",
        "**Ans:- s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'])---->r = pd.to_datetime(pd.Series(s))--->df = pd.DataFrame(r)**\n",
        "\n",
        "**Ques:-42.** Write a Pandas program to rename a specific column name in a given DataFrame.\n",
        "\n",
        "**Ans:- df=df.rename(columns = {'col2':'Column2'})**\n",
        "\n",
        "**Ques:-43.** Write a Pandas program to get a list of a specified column of a DataFrame.\n",
        "\n",
        "**Ans:- col2_list = df[\"col2\"].tolist()**\n",
        "\n",
        "**Ques:-44.** Write a Pandas program to create a DataFrame from a Numpy array and specify the index column and column headers.\n",
        "\n",
        "**Ans:- dtype = [('Column1','int32'), ('Column2','float32'), ('Column3','float32')]--->values = numpy.zeros(15, dtype=dtype)--->index = ['Index'+str(i) for i in range(1, len(values)+1)]--->df = pandas.DataFrame(values, index=index)**\n",
        "\n",
        "**Ques:-45.** Write a Pandas program to find the row for where the value of a given column is maximum.\n",
        "\n",
        "**Ans:- df['col1'].argmax()**\n",
        "\n",
        "**Ques:-46.** Write a Pandas program to check whether a given column is present in a DataFrame or not.\n",
        "\n",
        "**Ans:- if 'col4' in df.columns:\n",
        "  print(\"Col4 is present in DataFrame.\")\n",
        "else:\n",
        "  print(\"Col4 is not present in DataFrame.\")**\n",
        "\n",
        "**Ques:-47.** Write a Pandas program to get the specified row value of a given DataFrame.\n",
        "\n",
        "**Ans:-df.iloc[0]--row1---> df.iloc[3]--row4**\n",
        "\n",
        "**Ques:-48.** Write a Pandas program to get the datatypes of columns of a DataFrame.\n",
        "\n",
        "**Ans:- df.dtypes**\n",
        "\n",
        "**Ques:-49.** Write a Pandas program to append data to an empty DataFrame.\n",
        "\n",
        "**Ans:- df = pd.DataFrame()--->data = pd.DataFrame({\"col1\": range(3),\"col2\": range(3)})--->print(\"After appending some data:\")--->df = df.append(data)**\n",
        "\n",
        "**Ques:-50.** Write a Pandas program to sort a given DataFrame by two or more columns.\n",
        "\n",
        "**Ans:- df = df.sort_values(['attempts', 'name'], ascending=[True, True])**\n",
        "\n",
        "**Ques:-51.** Write a Pandas program to convert the datatype of a given column (floats to ints).\n",
        "\n",
        "**Ans:- df.score = df.score.astype(int)**--->Data type of 'score' column from float to int\n",
        "\n",
        "**Ques:-52.** Write a Pandas program to remove infinite values from a given DataFrame.\n",
        "\n",
        "**Ans:- df = pd.DataFrame([1000, 2000, 3000, -4000, np.inf, -np.inf])--->df = df.replace([np.inf, -np.inf], np.nan)**\n",
        "\n",
        "**Ques:-53**  Write a Pandas program to insert a given column at a specific column index in a DataFrame.\n",
        "\n",
        "**Ans:- d = {'col2': [4, 5, 6, 9, 5], 'col3': [7, 8, 12, 1, 11]}--->new_col = [1, 2, 3, 4, 7]--->df.insert(loc=0, column='col1', value=new_col)**---loc=0 means 1st column\n",
        "\n",
        "**Ques:-54**  Write a Pandas program to convert a given list of lists into a Dataframe.\n",
        "\n",
        "**Ans:- my_lists = [['col1', 'col2'], [2, 4], [1, 3]]---.# sets the headers as list--->headers = my_lists.pop(0) --->df = pd.DataFrame(my_lists, columns = headers)**--give header as column\n",
        "\n",
        "**Ques:-55** Write a Pandas program to group by the first column and get second column as lists in rows.\n",
        "\n",
        "**Ans:- df = pd.DataFrame( {'col1':['C1','C1','C2','C2','C2','C3','C2'], 'col2':[1,2,3,3,4,6,5]})----> df = df.groupby('col1')['col2'].apply(list)**\n",
        "\n",
        "**Ques:-56** Write a Pandas program to get column index from column name of a given DataFrame.\n",
        "\n",
        "**Ans:- d = {'col1': [1, 2, 3, 4, 7], 'col2': [4, 5, 6, 9, 5], 'col3': [7, 8, 12, 1, 11]}---->df.columns.get_loc(\"col2\")**\n",
        "\n",
        "**Ques:-57** Write a Pandas program to count number of columns of a DataFrame.\n",
        "\n",
        "**Ans:-len(df.columns)**\n",
        "\n",
        "**Ques:-58** Write a Pandas program to select all columns, except one given column in a DataFrame.\n",
        "\n",
        "**Ans:- df = df.loc[:, df.columns != 'col3']**\n",
        "\n",
        "**Ques:-59** Write a Pandas program to get first n records of a DataFrame.\n",
        "\n",
        "**Ans:- df.head(3)**\n",
        "\n",
        "**Ques:-60**  Write a Pandas program to get last n records of a DataFrame.\n",
        "\n",
        "**Ans:- df.tail(3)**\n",
        "\n",
        "**Ques:-61** Write a Pandas program to get topmost n records within each group of a DataFrame.\n",
        "\n",
        "**Ans:- df1 = df.nlargest(3, 'col1')--->df1 = df.nlargest(3, 'col2')--->df1 = df.nlargest(3, 'col3')**\n",
        "\n",
        "**Ques:-62** Write a Pandas program to remove first n rows of a given DataFrame.\n",
        "\n",
        "**Ans:- df1 = df.iloc[3:]**\n",
        "\n",
        "**Ques:-63** Write a Pandas program to remove last n rows of a given DataFrame.\n",
        "\n",
        "**Ans:- df1 = df.iloc[:3]**\n",
        "\n",
        "**Ques:-64** Write a Pandas program to add a prefix or suffix to all columns of a given DataFrame.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'W':[68,75,86,80,66],'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]})--->df.add_prefix(\"A_\")--->df.add_suffix(\"_1\")**--> it will give A_W for prefix and W_1 for suffix\n",
        "\n",
        "**Ques:-65** Write a Pandas program to reverse order (rows, columns) of a given DataFrame.\n",
        "\n",
        "**Ans:-** reverse column--> **df.loc[:, ::-1]** reverse row--> **df.loc[::-1]**-->Reverse row order and reset index--->**df.loc[::-1].reset_index(drop = True)**\n",
        "\n",
        "**Ques:-66.**  Write a Pandas program to select columns by data type of a given DataFrame.\n",
        "\n",
        "**Ans:-** for numeriacal-->**df.select_dtypes(include = \"number\")**---> for string--> **df.select_dtypes(include = \"object\")**\n",
        "\n",
        "**Ques:-67.** Write a Pandas program to split a given DataFrame into two random subsets.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],'date_of_birth': ['17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],'age': ['18', '21', '22', '22', '23']})-----> df_1 = df.sample(frac = 0.6)--->df_2 = df.drop(df_1.index)**\n",
        "\n",
        "**Ques:-68.**  Write a Pandas program to rename all columns with the same pattern of a given DataFrame.\n",
        "\n",
        "**Ans:- df.columns = df.columns.str.lower().str.rstrip()**--->Remove trailing (at the end) whitesapce and convert to lowercase of the columns name\n",
        "\n",
        "**Ques:-70.** Write a Pandas program to convert continuous values of a column in a given DataFrame to categorical.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Syed Wharton', 'Kierra Gentry'],'age': [18, 22, 85, 50, 80, 5]})-----df[\"age_groups\"] = pd.cut(df[\"age\"], bins = [0, 18, 65, 99], labels = [\"kids\", \"adult\", \"elderly\"])**\n",
        "\n",
        "**Ques:-72.**  Write a Pandas program to combine many given series to create a DataFrame.\n",
        "\n",
        "**Ans:-** **sr1 = pd.Series(['php', 'python', 'java', 'c#', 'c++'])---sr2 = pd.Series([1, 2, 3, 4, 5])**----**ser_df = pd.DataFrame(sr1, sr2).reset_index()**-->Combine above series to a dataframe-- **pd.concat([sr1, sr2], axis = 1)**-->Using pandas concat--**pd.DataFrame({\"col1\":sr1, \"col2\":sr2})**-->Using pandas DataFrame with a dictionary, gives a specific name to the columns\n",
        "\n",
        "**Ques:-74.** Write a Pandas program to fill missing values in time series data.\n",
        "\n",
        "From Wikipedia , in the mathematical field of numerical analysis, **interpolation** is a type of estimation, a method of constructing new data points within the range of a discrete set of known data points.\n",
        "\n",
        "**Ans:- sdata = {\"c1\":[120, 130 ,140, 150, np.nan, 170], \"c2\":[7, np.nan, 10, np.nan, 5.5, 16.5]}---df = pd.DataFrame(sdata)---df.index = pd.util.testing.makeDateIndex()[0:6]----df.interpolate()**\n",
        "\n",
        "**Ques:-76.** Write a Pandas program to clean object column with mixed data of a given DataFrame using regular expression.\n",
        "\n",
        "**Ans:- d = {\"agent\": [\"a001\", \"a002\", \"a003\", \"a003\", \"a004\"], \"purchase\":[4500.00, 7500.00, \"$3000.25\", \"$1250.35\", \"9000.00\"]}---df = pd.DataFrame(d)----df[\"purchase\"] = df[\"purchase\"].replace(\"[$,]\", \"\", regex = True).astype(\"float\")**\n",
        "\n",
        "**Ques:-77** Write a Pandas program to get the numeric representation of an array by identifying distinct values of a given column of a DataFrame.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'Name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill'],'Date_Of_Birth ': ['17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],'Age': [18.5, 21.2, 22.5, 22, 23]----label1, unique1 = pd.factorize(df['Name'])---print(label1)---print(unique1)**\n",
        "\n",
        "**Ques:-79**Write a Pandas program to create a DataFrame from the clipboard (data from an Excel spreadsheet or a Google Sheet).\n",
        "\n",
        "**Ans:- df = pd.read_clipboard()**\n",
        "\n",
        "**Ques:-80.** Write a Pandas program to check for inequality of two given DataFrames.\n",
        "\n",
        "**Ans:- df1 = pd.DataFrame({'W':[68,75,86,80,None],'X':[78,85,None,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]});---df2 = pd.DataFrame({'W':[78,75,86,80,None],'X':[78,85,96,80,76], 'Y':[84,84,89,83,86],'Z':[86,97,96,72,83]});---df1.ne(df2)**\n",
        "\n",
        "**Ques:-81.** Write a Pandas program to get lowest n records within each group of a given DataFrame.\n",
        "\n",
        "**Ans:- d = {'col1': [1, 2, 3, 4, 7, 11], 'col2': [4, 5, 6, 9, 5, 0], 'col3': [7, 5, 8, 12, 1,11]}---df1 = df.nsmallest(3, 'col1')---df1 = df.nsmallest(3, 'col2')---df1 = df.nsmallest(3, 'col3')**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FO10934UAGAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pandas Joining and merging DataFrame-**"
      ],
      "metadata": {
        "id": "yu_fL1_M0QOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "student_data1 = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
        "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
        "        'marks': [200, 210, 190, 222, 199]})\n",
        "\n",
        "student_data2 = pd.DataFrame({\n",
        "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
        "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
        "        'marks': [201, 200, 198, 219, 201]})\n",
        "\n",
        "exam_data = pd.DataFrame({\n",
        "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
        "        'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]})\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(student_data1)\n",
        "print(student_data2)\n",
        "print(exam_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwBfxN49VrSJ",
        "outputId": "5d045d33-b6ae-46e2-b3db-16b1e96d43e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrames:\n",
            "  student_id              name  marks\n",
            "0         S1  Danniella Fenton    200\n",
            "1         S2      Ryder Storey    210\n",
            "2         S3      Bryce Jensen    190\n",
            "3         S4         Ed Bernal    222\n",
            "4         S5       Kwame Morin    199\n",
            "  student_id              name  marks\n",
            "0         S4  Scarlette Fisher    201\n",
            "1         S5  Carla Williamson    200\n",
            "2         S6       Dante Morse    198\n",
            "3         S7    Kaiser William    219\n",
            "4         S8   Madeeha Preston    201\n",
            "   student_id  exam_id\n",
            "0          S1       23\n",
            "1          S2       45\n",
            "2          S3       12\n",
            "3          S4       67\n",
            "4          S5       21\n",
            "5          S7       55\n",
            "6          S8       33\n",
            "7          S9       14\n",
            "8         S10       56\n",
            "9         S11       83\n",
            "10        S12       88\n",
            "11        S13       12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-1.** Write a Pandas program to join the two given dataframes along rows and assign all data.\n",
        "\n",
        "**Ans:- result_data = pd.concat([student_data1, student_data2])**\n",
        "\n",
        "**Ques:-2.** Write a Pandas program to join the two given dataframes along columns and assign all data.\n",
        "\n",
        "**Ans:- result_data = pd.concat([student_data1, student_data2], axis = 1)**\n",
        "\n",
        "**Ques:-3.** Write a Pandas program to append rows to an existing DataFrame and display the combined data.\n",
        "\n",
        "**Ans:-** new row-- **s6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])**----**combined_data = student_data1.append(s6, ignore_index = True)**\n",
        "\n",
        "**Ques:-4** Write a Pandas program to append a list of dictioneries or series to a existing DataFrame and display the combined data.\n",
        "\n",
        "**Ans:- dicts = [{'student_id': 'S6', 'name': 'Scarlette Fisher', 'marks': 203}, {'student_id': 'S7', 'name': 'Bryce Jensen', 'marks': 207}]---combined_data =  student_data1.append(dicts, ignore_index=True, sort=False)**\n",
        "\n",
        "**Ques:-5.** Write a Pandas program to join the two given dataframes along rows and merge with another dataframe along the common column id.\n",
        "\n",
        "**Ans:-** Join first two said dataframes along rows---**result_data = pd.concat([student_data1, student_data2])**---Now join the said result_data and df_exam_data along student_id---**final_merged_data = pd.merge(result_data, exam_data, on='student_id')**\n",
        "\n",
        "**Ques:-6.**  Write a Pandas program to join the two dataframes using the common column of both dataframes.\n",
        "\n",
        "**Ans:- merged_data = pd.merge(student_data1, student_data2, on='student_id', how='inner')**\n",
        "\n",
        "**Ques:-7.** Write a Pandas program to join the two dataframes with matching records from both sides where available.\n",
        "\n",
        "**Ans:- merged_data = pd.merge(student_data1, student_data2, on='student_id', how='outer')**\n",
        "\n"
      ],
      "metadata": {
        "id": "3GKv4xwcVAFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
        "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
        "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
        "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']})\n",
        "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
        "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
        "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
        "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOEF8F2ratUW",
        "outputId": "febb3a90-01cc-4bbe-9761-644fa25855ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrames:\n",
            "  key1 key2   P   Q\n",
            "0   K0   K0  P0  Q0\n",
            "1   K0   K1  P1  Q1\n",
            "2   K1   K0  P2  Q2\n",
            "3   K2   K1  P3  Q3\n",
            "--------------------\n",
            "  key1 key2   R   S\n",
            "0   K0   K0  R0  S0\n",
            "1   K1   K0  R1  S1\n",
            "2   K1   K0  R2  S2\n",
            "3   K2   K0  R3  S3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-8** Write a Pandas program to join (left join) the two dataframes using keys from left dataframe only.\n",
        "\n",
        "**Ans:-** Merged Data (keys from data1)---**merged_data = pd.merge(data1, data2, how='left', on=['key1', 'key2'])***---Merged Data (keys from data2)---**merged_data = pd.merge(data2, data1, how='left', on=['key1', 'key2'])**\n",
        "\n",
        "**Ques:-9**  Write a Pandas program to join two dataframes using keys from right dataframe only.\n",
        "\n",
        "**Ans:-** Merged Data (keys from data2)---**merged_data = pd.merge(data1, data2, how='right', on=['key1', 'key2'])**----Merged Data (keys from data1)---**merged_data = pd.merge(data2, data1, how='right', on=['key1', 'key2'])**\n",
        "\n",
        "**Ques:-10.** Write a Pandas program to merge two given datasets using multiple join keys.\n",
        "\n",
        "**Ans:- merged_data = pd.merge(data1, data2, on=['key1', 'key2'])**\n",
        "\n",
        "**Ques:-11.** Write a Pandas program to create a new DataFrame based on existing series, using specified argument and override the existing columns names.\n",
        "\n",
        "**Ans:- s1 = pd.Series([0, 1, 2, 3], name='col1')---s2 = pd.Series([0, 1, 2, 3])---s3 = pd.Series([0, 1, 4, 5], name='col3')---df = pd.concat([s1, s2, s3], axis=1, keys=['column1', 'column2', 'column3'])**\n",
        "\n",
        "**Ques:-12.** Write a Pandas program to create a combination from two dataframes where a column id combination appears more than once in both dataframes.\n",
        "\n",
        "**Ans:-** Merged Data (many-to-many join case)---result = **pd.merge(data1, data2, on='key1')**\n",
        "\n"
      ],
      "metadata": {
        "id": "pcZBywUxa0vY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
        "                      'B': ['B0', 'B1', 'B2']},\n",
        "                     index=['K0', 'K1', 'K2'])\n",
        "\n",
        "data2 = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
        "                      'D': ['D0', 'D2', 'D3']},\n",
        "                     index=['K0', 'K2', 'K3'])\n",
        "\n",
        "print(\"Original DataFrames:\")\n",
        "print(data1)\n",
        "print(\"--------------------\")\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaZ2u7NWQoWi",
        "outputId": "e70dfb63-8e8d-479c-c4b7-23e3ae8b0ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrames:\n",
            "     A   B\n",
            "K0  A0  B0\n",
            "K1  A1  B1\n",
            "K2  A2  B2\n",
            "--------------------\n",
            "     C   D\n",
            "K0  C0  D0\n",
            "K2  C2  D2\n",
            "K3  C3  D3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-13.** Write a Pandas program to combine the columns of two potentially differently-indexed DataFrames into a single result DataFrame.\n",
        "\n",
        "**Ans:- result = data1.join(data2)**\n",
        "\n",
        "**Ques:-14.**  Write a Pandas program to merge two given dataframes with different columns.\n",
        "\n",
        "**Ans:- result = pd.concat([data1,data2], axis=0, ignore_index=True)**\n",
        "\n",
        "**Ques:-15.** Write a Pandas program to Combine two DataFrame objects by filling null values in one DataFrame with non-null values from other DataFrame.\n",
        "\n",
        "**Ans:- df1 = pd.DataFrame({'A': [None, 0, None], 'B': [3, 4, 5]})---df2 = pd.DataFrame({'A': [1, 1, 3], 'B': [3, None, 3]})---result = df1.combine_first(df2)**"
      ],
      "metadata": {
        "id": "b08XkdrJQ1DW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pandas Grouping and Aggregating-**"
      ],
      "metadata": {
        "id": "j7r90Yd3SxAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(student_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3IBrEFTwWS",
        "outputId": "74c551d3-4227-490c-e917-7d1b4bd802be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
            "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
            "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
            "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
            "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
            "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
            "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
            "\n",
            "    address  \n",
            "S1  street1  \n",
            "S2  street2  \n",
            "S3  street3  \n",
            "S4  street1  \n",
            "S5  street2  \n",
            "S6  street4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-1.** Write a Pandas program to split the following dataframe into groups based on school code. Also check the type of GroupBy object.\n",
        "\n",
        "**Ans:- result = student_data.groupby(['school_code'])--for name,group in result:--print(name)---print(group)**---Type of the object--**type(result)**\n",
        "\n",
        "**Ques:-2.** Write a Pandas program to split the following dataframe by school code and get mean, min, and max value of age for each school.\n",
        "\n",
        "**Ans:- grouped_single = student_data.groupby('school_code').agg({'age': ['mean', 'min', 'max']})**\n",
        "\n",
        "**Ques:-4.** Write a Pandas program to split the following given dataframe into groups based on single column and multiple columns. Find the size of the grouped data.\n",
        "\n",
        "**Ans:-** Split the said data on school_code wise---**grouped_single = student_data.groupby(['school_code'])**---Size of the grouped data - single column---**grouped_single.size()**---Split the said data on school_code and class wise---**grouped_mul = student_data.groupby(['school_code', 'class'])**---Size of the grouped data - multiple columns---**grouped_mul.size()**\n",
        "\n",
        "**Ques:-6.** Write a Pandas program to split the following given dataframe into groups based on school code and call a specific group with the name of the group.\n",
        "\n",
        "**Ans:-** Split the said data on school_code wise--**grouped = student_data.groupby(['school_code'])**---Call school code 's001'---**grouped.get_group('s001')**\n"
      ],
      "metadata": {
        "id": "s4_Ju-SKS95z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "orders_data = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(orders_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqpXOkABabQ0",
        "outputId": "7d95a690-d4d3-4c3c-e417-2fd026d7cb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0    70001     150.50  2012-10-05         3005         5002\n",
            "1    70009     270.65  2012-09-10         3001         5005\n",
            "2    70002      65.26  2012-10-05         3002         5001\n",
            "3    70004     110.50  2012-08-17         3009         5003\n",
            "4    70007     948.50  2012-09-10         3005         5002\n",
            "5    70005    2400.60  2012-07-27         3007         5001\n",
            "6    70008    5760.00  2012-09-10         3002         5001\n",
            "7    70010    1983.43  2012-10-10         3004         5006\n",
            "8    70003    2480.40  2012-10-10         3009         5003\n",
            "9    70012     250.45  2012-06-27         3008         5002\n",
            "10   70011      75.29  2012-08-17         3003         5007\n",
            "11   70013    3045.60  2012-04-25         3002         5001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-7.** Write a Pandas program to split a dataset, group by one column and get mean, min, and max values by group. Using the following dataset find the mean, min, and max values of purchase amount (purch_amt) group by customer id (customer_id).\n",
        "\n",
        "**Ans:- result = orders_data.groupby('customer_id').agg({'purch_amt': ['mean', 'min', 'max']})**\n",
        "\n",
        "**Ques:-8.** Write a Pandas program to split a dataset to group by two columns and count by each row.\n",
        "\n",
        "**Ans:-** Group by two columns and count by each row---**result = orders_data.groupby(['salesman_id','customer_id']).size().reset_index().groupby(['salesman_id','customer_id'])[[0]].max()**\n",
        "\n",
        "**Ques:-9.** Write a Pandas program to split a dataset to group by two columns and then sort the aggregated results within the groups.\n",
        "In the following dataset group on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups.\n",
        "\n",
        "**Ans:- **df_agg = df.groupby(['customer_id','salesman_id']).agg({'purch_amt':sum})---result = df_agg['purch_amt'].groupby(level=0, group_keys=False)**----**result.nlargest()**\n",
        "\n",
        "**Ques:-10.** Write a Pandas program to split the following dataframe into groups based on customer id and create a list of order date for each group.\n",
        "\n",
        "**Ans:- result = df.groupby('customer_id')['ord_date'].apply(list)**\n",
        "\n",
        "**Ques:-11.** Write a Pandas program to split the following dataframe into groups and calculate monthly purchase amount.\n",
        "\n",
        "**Ans:- df['ord_date']= pd.to_datetime(df['ord_date'])**---Month wise purchase amount---**result = df.set_index('ord_date').groupby(pd.Grouper(freq='M')).agg({'purch_amt':sum})**\n",
        "\n",
        "**Ques:-12.** Write a Pandas program to split the following dataframe into groups, group by month and year based on order date and find the total purchase amount year wise, month wise.\n",
        "\n",
        "**Ans:- df['ord_date']= pd.to_datetime(df['ord_date'])**----**result = df.groupby([df['ord_date'].dt.year, df['ord_date'].dt.month]).agg({'purch_amt':sum})**\n",
        "\n",
        "**Ques:-13.** Write a Pandas program to split the following dataframe into groups based on first column and set other column values into a list of values.\n",
        "\n",
        "**Ans:- df = pd.DataFrame( {'X' : [10, 10, 10, 20, 30, 30, 10], 'Y' : [10, 15, 11, 20, 21, 12, 14], 'Z' : [22, 20, 18, 20, 13, 10, 0]})------result= df.groupby('X').aggregate(lambda tdf: tdf.unique().tolist())**\n",
        "\n",
        "**Ques:-14.** Write a Pandas program to split the following dataframe into groups and count unique values of 'value' column.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'id': [1, 1, 2, 3, 3, 4, 4, 4],'value': ['a', 'a', 'b', None, 'a', 'a', None, 'b']------df.groupby('value')['id'].nunique()**\n",
        "\n",
        "**Ques:-15.** Write a Pandas program to split the following dataframe into groups based on all columns and calculate Groupby value counts on the dataframe.\n",
        "\n",
        "**Ans:- df = pd.DataFrame( {'id' : [1, 2, 1, 1, 2, 1, 2], 'type' : [10, 15, 11, 20, 21, 12, 14], 'book' : ['Math','English','Physics','Math','English','Physics','English']})---->result = df.groupby(['id', 'type', 'book']).size().unstack(fill_value=0)**\n",
        "\n",
        "**Ques:-16.** Write a Pandas program to split a given dataframe into groups and list all the keys from the GroupBy object.\n",
        "\n",
        "**Ans:- gp = df.groupby('school_code')---->gp.groups.keys()**\n",
        "\n",
        "**Ques:-17.** Write a Pandas program to split a given dataframe into groups and create a new column with count from GroupBy.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'book_name':['Book1','Book2','Book3','Book4','Book1','Book2','Book3','Book5'],'book_type':['Math','Physics','Computer','Science','Math','Physics','Computer','English'],'book_id':[1,2,3,4,1,2,3,5]})-----result = df.groupby([\"book_name\", \"book_type\"])[\"book_type\"].count().reset_index(name=\"count\")**\n",
        "\n",
        "**Ques:-18.** Write a Pandas program to split a given dataframe into groups with bin counts.\n",
        "\n",
        "**Ans:- groups = df.groupby(['customer_id', pd.cut(df.sales_id, 3)])\n",
        "result = groups.size().unstack()**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sZVON-yNasSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s001'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL6IdTG3Vuig",
        "outputId": "95c94fdb-3248-45a6-b8c9-72ccca9ff4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
            "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
            "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
            "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
            "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
            "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
            "S6        s001    VI    David Parkes     15/09/1997   12     159      32   \n",
            "\n",
            "    address  \n",
            "S1  street1  \n",
            "S2  street2  \n",
            "S3  street3  \n",
            "S4  street1  \n",
            "S5  street2  \n",
            "S6  street4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-19.** Write a Pandas program to split a given dataframe into groups with multiple aggregations.Split the following given dataframe by school code, class and get mean, min, and max value of height and age for each value of the school.\n",
        "\n",
        "**Ans:- result = df.groupby(['school_code','class']).agg({'height': ['max', 'mean'],'weight': ['sum','min','count']})**"
      ],
      "metadata": {
        "id": "ljpJriedV8PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Ques:-20:-Write a Pandas program to split a given dataframe into groups and display target column as a list of unique values.'''\n",
        "\n",
        "df = pd.DataFrame( {'id' : ['A','A','A','A','A','A','B','B','B','B','B'],\n",
        "                    'type' : [1,1,1,1,2,2,1,1,1,2,2],\n",
        "                    'book' : ['Math','Math','English','Physics','Math','English','Physics','English','Physics','English','English']})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "new_df = df[['id', 'type', 'book']].drop_duplicates()\\\n",
        "                         .groupby(['id','type'])['book']\\\n",
        "                         .apply(list)\\\n",
        "                         .reset_index()\n",
        "\n",
        "new_df['book'] = new_df.apply(lambda x: (','.join([str(s) for s in x['book']])), axis = 1)\n",
        "print(\"\\nList all unique values in a group:\")\n",
        "print(new_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNQxbiXZWxC7",
        "outputId": "f215b44d-8fe2-4aa0-a846-cf8ae10b87be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   id  type     book\n",
            "0   A     1     Math\n",
            "1   A     1     Math\n",
            "2   A     1  English\n",
            "3   A     1  Physics\n",
            "4   A     2     Math\n",
            "5   A     2  English\n",
            "6   B     1  Physics\n",
            "7   B     1  English\n",
            "8   B     1  Physics\n",
            "9   B     2  English\n",
            "10  B     2  English\n",
            "\n",
            "List all unique values in a group:\n",
            "  id  type                  book\n",
            "0  A     1  Math,English,Physics\n",
            "1  A     2          Math,English\n",
            "2  B     1       Physics,English\n",
            "3  B     2               English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-20.** Write a Pandas program to split a given dataframe into groups and display target column as a list of unique values.\n",
        "\n",
        "**Ans:- df = pd.DataFrame( {'id' : ['A','A','A','A','A','A','B','B','B','B','B'], 'type' : [1,1,1,1,2,2,1,1,1,2,2], 'book' : ['Math','Math','English','Physics','Math','English','Physics','English','Physics','English','English']})----->new_df = df[['id', 'type', 'book']].drop_duplicates().groupby(['id','type'])['book'].apply(list).reset_index()----->new_df['book'] = new_df.apply(lambda x: (','.join([str(s) for s in x['book']])), axis = 1)---->print(new_df)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s41DYdiOZIIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so8cKPrxaoKa",
        "outputId": "6b7564a6-d429-4bc0-d317-77f17e65ba84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0    70001     150.50  05-10-2012         3001         5002\n",
            "1    70009     270.65  09-10-2012         3001         5005\n",
            "2    70002      65.26  05-10-2012         3005         5001\n",
            "3    70004     110.50  08-17-2012         3001         5003\n",
            "4    70007     948.50  10-09-2012         3005         5002\n",
            "5    70005    2400.60  07-27-2012         3001         5001\n",
            "6    70008    5760.00  10-09-2012         3005         5001\n",
            "7    70010    1983.43  10-10-2012         3001         5006\n",
            "8    70003    2480.40  10-10-2012         3005         5003\n",
            "9    70012     250.45  06-17-2012         3001         5002\n",
            "10   70011      75.29  07-08-2012         3005         5007\n",
            "11   70013    3045.60  04-25-2012         3005         5001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-21.** Write a Pandas program to split the following dataframe into groups and calculate quarterly purchase amount.\n",
        "\n",
        "**Ans:- df['ord_date']= pd.to_datetime(df['ord_date'])---->result = df.set_index('ord_date').groupby(pd.Grouper(freq='Q')).agg({'purch_amt':sum})**\n",
        "\n"
      ],
      "metadata": {
        "id": "Nyh8N376a3lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "student_data = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    ' height ': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(student_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lndl0pYOD4y",
        "outputId": "b4aff998-a6d1-467b-ab2a-ccb31cfa1b4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   school_code class            name date_Of_Birth   age   height   weight  \\\n",
            "S1        s001     V  Alberto Franco     15/05/2002   12       173      35   \n",
            "S2        s002     V    Gino Mcneill     17/05/2002   12       192      32   \n",
            "S3        s003    VI     Ryan Parkes     16/02/1999   13       186      33   \n",
            "S4        s001    VI    Eesha Hinton     25/09/1998   13       167      30   \n",
            "S5        s002     V    Gino Mcneill     11/05/2002   14       151      31   \n",
            "S6        s004    VI    David Parkes     15/09/1997   12       159      32   \n",
            "\n",
            "    address  \n",
            "S1  street1  \n",
            "S2  street2  \n",
            "S3  street3  \n",
            "S4  street1  \n",
            "S5  street2  \n",
            "S6  street4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-22.**  Write a Pandas program to split the following dataframe into groups by school code and get mean, min, and max value of age with customized column name for each school.\n",
        "\n",
        "**Ans:- grouped_single = student_data.groupby('school_code').agg(Age_Mean = ('age','mean'),Age_Max=('age',max),Age_Min=('age',min))**\n",
        "\n"
      ],
      "metadata": {
        "id": "bogMnzP6OPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
        "'customer_id':['C3001','C3001','D3005','D3001','C3005','D3001','C3005','D3001','D3005','C3001','D3005','D3005'],\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F17p8FNvRf_2",
        "outputId": "40dd7336-9f74-4531-f637-b998b6d47ef3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "    ord_no  purch_amt    ord_date customer_id  salesman_id\n",
            "0    70001     150.50  05-10-2012       C3001         5002\n",
            "1    70009     270.65  09-10-2012       C3001         5005\n",
            "2    70002      65.26  05-10-2012       D3005         5001\n",
            "3    70004     110.50  08-17-2012       D3001         5003\n",
            "4    70007     948.50  10-09-2012       C3005         5002\n",
            "5    70005    2400.60  07-27-2012       D3001         5001\n",
            "6    70008    5760.00  10-09-2012       C3005         5001\n",
            "7    70010    1983.43  10-10-2012       D3001         5006\n",
            "8    70003    2480.40  10-10-2012       D3005         5003\n",
            "9    70012     250.45  06-17-2012       C3001         5002\n",
            "10   70011      75.29  07-08-2012       D3005         5007\n",
            "11   70013    3045.60  04-25-2012       D3005         5001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-23.** Write a Pandas program to split the following datasets into groups on customer id and calculate the number of customers starting with 'C', the list of all products and the difference of maximum purchase amount and minimum purchase amount\n",
        "\n",
        "**Ans:- def customer_id_C(x):---return (x.str[0] == 'C').sum()---->result = df.groupby(['salesman_id']).agg(customer_id_start_C = ('customer_id', customer_id_C),customer_id_list = ('customer_id', lambda x: ', '.join(x)),purchase_amt_gap   = ('purch_amt', lambda x: x.max()-x.min()))--->result**\n",
        "\n",
        "**Ques:-24.** Write a Pandas program to split the following datasets into groups on customer_id to summarize purch_amt and calculate percentage of purch_amt in each group.\n",
        "\n",
        "**Ans:- gr_data = df.groupby(['customer_id','salesman_id']).agg({'purch_amt': 'sum'})--gr_data[\"% (Purch Amt.)\"] = gr_data.apply(lambda x:  100*x / x.sum())---->gr_data**\n",
        "\n"
      ],
      "metadata": {
        "id": "plzKeWrWRjd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
        "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
        "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
        "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
        "    'age': [12, 12, 13, 13, 14, 12],\n",
        "    'height': [173, 192, 186, 167, 151, 159],\n",
        "    'weight': [35, 32, 33, 30, 31, 32],\n",
        "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
        "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYnjIqKOS6bl",
        "outputId": "e0c91333-7626-4df5-ac0d-df4c48b0eced"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
            "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
            "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
            "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
            "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
            "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
            "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
            "\n",
            "    address  \n",
            "S1  street1  \n",
            "S2  street2  \n",
            "S3  street3  \n",
            "S4  street1  \n",
            "S5  street2  \n",
            "S6  street4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-25.** Write a Pandas program to split a dataset, group by one column and get mean, min, and max values by group, also change the column name of the aggregated metric. Using the following dataset find the mean, min, and max values of purchase amount (purch_amt) group by customer id (customer_id).\n",
        "\n",
        "**Ans:- grouped_single = df.groupby('school_code').agg({'age': [(\"mean_age\",\"mean\"), (\"min_age\", \"min\"), (\"max_age\",\"max\")]})**\n",
        "\n"
      ],
      "metadata": {
        "id": "W4jBRuKCTPkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Ques:-26.** Write a Pandas program to split a given dataset, group by two columns and\n",
        "# convert other columns of the dataframe into a dictionary with column header as key.\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "dict_data_list = list()\n",
        "\n",
        "for gg, dd in df.groupby(['school_code','class']):\n",
        "    group = dict(zip(['school_code','class'], gg))\n",
        "    ocolumns_list = list()\n",
        "    for _, data in dd.iterrows():\n",
        "        data = data.drop(labels=['school_code','class'])\n",
        "        ocolumns_list.append(data.to_dict())\n",
        "    group['other_columns'] = ocolumns_list\n",
        "    dict_data_list.append(group)\n",
        "\n",
        "print(dict_data_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "926VOUxUUMr4",
        "outputId": "548dfe3d-4461-4364-a4fd-07f5c3574aa7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
            "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
            "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
            "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
            "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
            "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
            "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
            "\n",
            "    address  \n",
            "S1  street1  \n",
            "S2  street2  \n",
            "S3  street3  \n",
            "S4  street1  \n",
            "S5  street2  \n",
            "S6  street4  \n",
            "[{'school_code': 's001', 'class': 'V', 'other_columns': [{'name': 'Alberto Franco', 'date_Of_Birth ': '15/05/2002', 'age': 12, 'height': 173, 'weight': 35, 'address': 'street1'}]}, {'school_code': 's001', 'class': 'VI', 'other_columns': [{'name': 'Eesha Hinton', 'date_Of_Birth ': '25/09/1998', 'age': 13, 'height': 167, 'weight': 30, 'address': 'street1'}]}, {'school_code': 's002', 'class': 'V', 'other_columns': [{'name': 'Gino Mcneill', 'date_Of_Birth ': '17/05/2002', 'age': 12, 'height': 192, 'weight': 32, 'address': 'street2'}, {'name': 'Gino Mcneill', 'date_Of_Birth ': '11/05/2002', 'age': 14, 'height': 151, 'weight': 31, 'address': 'street2'}]}, {'school_code': 's003', 'class': 'VI', 'other_columns': [{'name': 'Ryan Parkes', 'date_Of_Birth ': '16/02/1999', 'age': 13, 'height': 186, 'weight': 33, 'address': 'street3'}]}, {'school_code': 's004', 'class': 'VI', 'other_columns': [{'name': 'David Parkes', 'date_Of_Birth ': '15/09/1997', 'age': 12, 'height': 159, 'weight': 32, 'address': 'street4'}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a Pandas program to split a given dataset,\n",
        "#group by one column and apply an aggregate function to few columns and another aggregate function to the rest of the columns of the dataframe.\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001],\n",
        "'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6],\n",
        "'sale_feb':[250.5, 170.65, 15.26, 110.5, 598.5, 1400.6, 2760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_mar':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_apr':[150.5, 270.65, 95.26, 210.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_may':[130.5, 270.65, 65.26, 310.5, 948.5, 2400.6, 760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_jun':[150.5, 270.65, 45.26, 110.5, 948.5, 3400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_jul':[950.5, 270.65, 65.26, 210.5, 948.5, 2400.6, 5760, 983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_aug':[150.5, 70.65,  65.26, 110.5, 948.5, 400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_sep':[150.5, 270.65, 65.26, 110.5, 948.5, 200.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_oct':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_nov':[150.5, 270.65, 95.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6],\n",
        "'sale_dec':[150.5, 70.65, 65.26, 110.5, 948.5, 2400.6, 5760, 1983.43, 2480.4, 250.45, 75.29, 3045.6]\n",
        "})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\Result after group on salesman_id and apply different aggregate functions:\")\n",
        "df = df.groupby('salesman_id').agg(lambda x : x.sum() if x.name in ['sale_jan','sale_feb','sale_mar'] else x.mean())\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdmI6fDNVOzy",
        "outputId": "3212ef5c-32bb-4a62-a382-191af0c71bd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "    salesman_id  sale_jan  sale_feb  sale_mar  sale_apr  sale_may  sale_jun  \\\n",
            "0          5002    150.50    250.50    150.50    150.50    130.50    150.50   \n",
            "1          5005    270.65    170.65    270.65    270.65    270.65    270.65   \n",
            "2          5001     65.26     15.26     65.26     95.26     65.26     45.26   \n",
            "3          5003    110.50    110.50    110.50    210.50    310.50    110.50   \n",
            "4          5002    948.50    598.50    948.50    948.50    948.50    948.50   \n",
            "5          5001   2400.60   1400.60   2400.60   2400.60   2400.60   3400.60   \n",
            "6          5001   1760.00   2760.00   5760.00    760.00    760.00   5760.00   \n",
            "7          5006   2983.43   1983.43   1983.43   1983.43   1983.43    983.43   \n",
            "8          5003    480.40   2480.40   2480.40   2480.40   2480.40   2480.40   \n",
            "9          5002   1250.45    250.45    250.45    250.45    250.45    250.45   \n",
            "10         5007     75.29     75.29     75.29     75.29     75.29     75.29   \n",
            "11         5001   1045.60   3045.60   3045.60   3045.60   3045.60   3045.60   \n",
            "\n",
            "    sale_jul  sale_aug  sale_sep  sale_oct  sale_nov  sale_dec  \n",
            "0     950.50    150.50    150.50    150.50    150.50    150.50  \n",
            "1     270.65     70.65    270.65    270.65    270.65     70.65  \n",
            "2      65.26     65.26     65.26     65.26     95.26     65.26  \n",
            "3     210.50    110.50    110.50    110.50    110.50    110.50  \n",
            "4     948.50    948.50    948.50    948.50    948.50    948.50  \n",
            "5    2400.60    400.60    200.60   2400.60   2400.60   2400.60  \n",
            "6    5760.00   5760.00   5760.00   5760.00   5760.00   5760.00  \n",
            "7     983.43   1983.43   1983.43   1983.43   1983.43   1983.43  \n",
            "8    2480.40   2480.40   2480.40   2480.40   2480.40   2480.40  \n",
            "9     250.45    250.45    250.45    250.45    250.45    250.45  \n",
            "10     75.29     75.29     75.29     75.29     75.29     75.29  \n",
            "11   3045.60   3045.60   3045.60   3045.60   3045.60   3045.60  \n",
            "\\Result after group on salesman_id and apply different aggregate functions:\n",
            "             sale_jan  sale_feb  sale_mar     sale_apr  sale_may     sale_jun  \\\n",
            "salesman_id                                                                     \n",
            "5001          5271.46   7221.46  11271.46  1575.365000  1567.865  3062.865000   \n",
            "5002          2349.45   1099.45   1349.45   449.816667   443.150   449.816667   \n",
            "5003           590.90   2590.90   2590.90  1345.450000  1395.450  1295.450000   \n",
            "5005           270.65    170.65    270.65   270.650000   270.650   270.650000   \n",
            "5006          2983.43   1983.43   1983.43  1983.430000  1983.430   983.430000   \n",
            "5007            75.29     75.29     75.29    75.290000    75.290    75.290000   \n",
            "\n",
            "                sale_jul     sale_aug     sale_sep     sale_oct     sale_nov  \\\n",
            "salesman_id                                                                    \n",
            "5001         2817.865000  2317.865000  2267.865000  2817.865000  2825.365000   \n",
            "5002          716.483333   449.816667   449.816667   449.816667   449.816667   \n",
            "5003         1345.450000  1295.450000  1295.450000  1295.450000  1295.450000   \n",
            "5005          270.650000    70.650000   270.650000   270.650000   270.650000   \n",
            "5006          983.430000  1983.430000  1983.430000  1983.430000  1983.430000   \n",
            "5007           75.290000    75.290000    75.290000    75.290000    75.290000   \n",
            "\n",
            "                sale_dec  \n",
            "salesman_id               \n",
            "5001         2817.865000  \n",
            "5002          449.816667  \n",
            "5003         1295.450000  \n",
            "5005           70.650000  \n",
            "5006         1983.430000  \n",
            "5007           75.290000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-28.** Write a Pandas program to split a given dataset, group by one column and remove those groups if all the values of a specific columns are not available.\n",
        "\n",
        "**Ans:-** Group by one column and remove those groups if all the values of a specific columns are not available---**result = df[(~df['height'].isna()).groupby(df['school_code']).transform('any')]**\n",
        "\n",
        "**Ques:-29.** Write a Pandas program to split a given dataset using group by on specified column into two labels and ranges.\n",
        "Split the group on 'salesman_id',\n",
        "Ranges:\n",
        "1) (5001...5006)\n",
        "2) (5007..5012)\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'salesman_id': [5001,5002,5003,5004,5005,5006,5007,5008,5009,5010,5011,5012],'sale_jan':[150.5, 270.65, 65.26, 110.5, 948.5, 2400.6, 1760, 2983.43, 480.4,  1250.45, 75.29,1045.6]})----result = df.groupby(pd.cut(df['salesman_id'], bins=[0,5006,np.inf],  labels=['S1', 'S2']))['sale_jan'].sum().reset_index()**\n",
        "\n",
        "**Ques:-30.** Write a Pandas program to split the following dataset using group by on first column and aggregate over multiple lists on second column.\n",
        "\n",
        "**Ans:- df = pd.DataFrame({'student_id': ['S001','S001','S002','S002','S003','S003'],'marks': [[88,89,90],[78,81,60],[84,83,91],[84,88,91],[90,89,92],[88,59,90]]})---->result = df.set_index('student_id')['marks'].groupby('student_id').apply(list).apply(lambda x: np.mean(x,0))**\n",
        "\n",
        "**Ques:-31.** Write a Pandas program to split the following dataset using group by on 'salesman_id' and find the first order date for each group.\n",
        "\n",
        "**Ans:- result = df.groupby('salesman_id')['ord_date'].min()**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sxNjolb2WAtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques-32. Write a Pandas program to split a given dataset using group by on multiple columns and drop last n rows of from each group.\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3002,3001,3001,3003,3002,3002,3001,3004,3003,3002,3003,3001],\n",
        "'salesman_id':[5002,5003,5001,5003,5002,5001,5001,5003,5003,5002,5003,5001]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nSplit the said data on 'salesman_id', 'customer_id' wise:\")\n",
        "result = df.groupby(['salesman_id', 'customer_id'])\n",
        "for name,group in result:\n",
        "    print(\"\\nGroup:\")\n",
        "    print(name)\n",
        "    print(group)\n",
        "n = 2\n",
        "#result1 = df.groupby(['salesman_id', 'customer_id']).tail(n).index, axis=0)\n",
        "print(\"\\nDroping last two records:\")\n",
        "result1 = df.drop(df.groupby(['salesman_id', 'customer_id']).tail(n).index, axis=0)\n",
        "print(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlRWD6fWYMG5",
        "outputId": "420aba4d-5eb0-47bb-a576-c480aa259d0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0    70001     150.50  2012-10-05         3002         5002\n",
            "1    70009     270.65  2012-09-10         3001         5003\n",
            "2    70002      65.26  2012-10-05         3001         5001\n",
            "3    70004     110.50  2012-08-17         3003         5003\n",
            "4    70007     948.50  2012-09-10         3002         5002\n",
            "5    70005    2400.60  2012-07-27         3002         5001\n",
            "6    70008    5760.00  2012-09-10         3001         5001\n",
            "7    70010    1983.43  2012-10-10         3004         5003\n",
            "8    70003    2480.40  2012-10-10         3003         5003\n",
            "9    70012     250.45  2012-06-27         3002         5002\n",
            "10   70011      75.29  2012-08-17         3003         5003\n",
            "11   70013    3045.60  2012-04-25         3001         5001\n",
            "\n",
            "Split the said data on 'salesman_id', 'customer_id' wise:\n",
            "\n",
            "Group:\n",
            "(5001, 3001)\n",
            "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "2    70002      65.26  2012-10-05         3001         5001\n",
            "6    70008    5760.00  2012-09-10         3001         5001\n",
            "11   70013    3045.60  2012-04-25         3001         5001\n",
            "\n",
            "Group:\n",
            "(5001, 3002)\n",
            "   ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "5   70005     2400.6  2012-07-27         3002         5001\n",
            "\n",
            "Group:\n",
            "(5002, 3002)\n",
            "   ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0   70001     150.50  2012-10-05         3002         5002\n",
            "4   70007     948.50  2012-09-10         3002         5002\n",
            "9   70012     250.45  2012-06-27         3002         5002\n",
            "\n",
            "Group:\n",
            "(5003, 3001)\n",
            "   ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "1   70009     270.65  2012-09-10         3001         5003\n",
            "\n",
            "Group:\n",
            "(5003, 3003)\n",
            "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "3    70004     110.50  2012-08-17         3003         5003\n",
            "8    70003    2480.40  2012-10-10         3003         5003\n",
            "10   70011      75.29  2012-08-17         3003         5003\n",
            "\n",
            "Group:\n",
            "(5003, 3004)\n",
            "   ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "7   70010    1983.43  2012-10-10         3004         5003\n",
            "\n",
            "Droping last two records:\n",
            "   ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0   70001     150.50  2012-10-05         3002         5002\n",
            "2   70002      65.26  2012-10-05         3001         5001\n",
            "3   70004     110.50  2012-08-17         3003         5003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pandas Handling Missing Values-**"
      ],
      "metadata": {
        "id": "FhL4_wLhRa_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
        "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2UJHVgMR-ra",
        "outputId": "49fc79b4-4fa4-4e37-9c8e-7b8889dbf018"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
            "1       NaN     270.65  2012-09-10         3001       5003.0\n",
            "2   70002.0      65.26         NaN         3001       5001.0\n",
            "3   70004.0     110.50  2012-08-17         3003          NaN\n",
            "4       NaN     948.50  2012-09-10         3002       5002.0\n",
            "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
            "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
            "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
            "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
            "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
            "10      NaN      75.29  2012-08-17         3001       5003.0\n",
            "11  70013.0    3045.60  2012-04-25         3001          NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-1.**Write a Pandas program to detect missing values of a given DataFrame. Display True or False.\n",
        "\n",
        "**Ans:- df.isna()**\n",
        "\n",
        "**Ques:-2.** Write a Pandas program to identify the column(s) of a given DataFrame which have at least one missing value.\n",
        "\n",
        "**Ans:- df.isna().any()**\n",
        "\n",
        "**Ques:-3.** Write a Pandas program to count the number of missing values in each column of a given DataFrame.\n",
        "\n",
        "**Ans:- df.isna().sum()**\n",
        "\n"
      ],
      "metadata": {
        "id": "QrUrYsRuRjIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Ques:-4.** Write a Pandas program to find and replace the missing values in a given DataFrame which do not have any valuable information.\n",
        "\n",
        "# Ans:-\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,\"--\",70010,70003,70012,np.nan,70013],\n",
        "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,\"?\",12.43,2480.4,250.45, 3045.6],\n",
        "'ord_date': ['?','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,\"--\",3002,3001,3001],\n",
        "'salesman_id':[5002,5003,\"?\",5001,np.nan,5002,5001,\"?\",5003,5002,5003,\"--\"]})\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nReplace the missing values with NaN:\")\n",
        "result = df.replace({\"?\": np.nan, \"--\": np.nan})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqU1kZheTfeq",
        "outputId": "1201ce24-bc10-419f-9c8e-174cb533eb59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "   ord_no purch_amt    ord_date customer_id salesman_id\n",
            "0   70001     150.5           ?        3002        5002\n",
            "1     NaN    270.65  2012-09-10        3001        5003\n",
            "2   70002     65.26         NaN        3001           ?\n",
            "3   70004     110.5  2012-08-17        3003        5001\n",
            "4     NaN     948.5  2012-09-10        3002         NaN\n",
            "5   70005    2400.6  2012-07-27        3001        5002\n",
            "6      --      5760  2012-09-10        3001        5001\n",
            "7   70010         ?  2012-10-10        3004           ?\n",
            "8   70003     12.43  2012-10-10          --        5003\n",
            "9   70012    2480.4  2012-06-27        3002        5002\n",
            "10    NaN    250.45  2012-08-17        3001        5003\n",
            "11  70013    3045.6  2012-04-25        3001          --\n",
            "\n",
            "Replace the missing values with NaN:\n",
            "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
            "0   70001.0     150.50         NaN       3002.0       5002.0\n",
            "1       NaN     270.65  2012-09-10       3001.0       5003.0\n",
            "2   70002.0      65.26         NaN       3001.0          NaN\n",
            "3   70004.0     110.50  2012-08-17       3003.0       5001.0\n",
            "4       NaN     948.50  2012-09-10       3002.0          NaN\n",
            "5   70005.0    2400.60  2012-07-27       3001.0       5002.0\n",
            "6       NaN    5760.00  2012-09-10       3001.0       5001.0\n",
            "7   70010.0        NaN  2012-10-10       3004.0          NaN\n",
            "8   70003.0      12.43  2012-10-10          NaN       5003.0\n",
            "9   70012.0    2480.40  2012-06-27       3002.0       5002.0\n",
            "10      NaN     250.45  2012-08-17       3001.0       5003.0\n",
            "11  70013.0    3045.60  2012-04-25       3001.0          NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-5.** Write a Pandas program to drop the rows where at least one element is missing in a given DataFrame.\n",
        "\n",
        "**Ans:- result = df.dropna()**\n",
        "\n",
        "**Ques:-6.** Write a Pandas program to drop the columns where at least one element is missing in a given DataFrame\n",
        "\n",
        "**Ans:- result = df.dropna(axis='columns')**\n",
        "\n"
      ],
      "metadata": {
        "id": "2xFt9Hx8UAVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques:-7. Write a Pandas program to drop the rows where all elements are missing in a given DataFrame.\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df = pd.DataFrame({\n",
        "'ord_no':[np.nan,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
        "'purch_amt':[np.nan,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
        "'ord_date': [np.nan,'2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
        "'customer_id':[np.nan,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001]})\n",
        "\n",
        "print(\"Original Orders DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nDrop the rows where all elements are missing:\")\n",
        "result = df.dropna(how='all')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40SHEoiaWzsk",
        "outputId": "38f23ca8-df33-4f3d-bc26-ece484937478"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Orders DataFrame:\n",
            "     ord_no  purch_amt    ord_date  customer_id\n",
            "0       NaN        NaN         NaN          NaN\n",
            "1       NaN     270.65  2012-09-10       3001.0\n",
            "2   70002.0      65.26         NaN       3001.0\n",
            "3   70004.0     110.50  2012-08-17       3003.0\n",
            "4       NaN     948.50  2012-09-10       3002.0\n",
            "5   70005.0    2400.60  2012-07-27       3001.0\n",
            "6       NaN    5760.00  2012-09-10       3001.0\n",
            "7   70010.0    1983.43  2012-10-10       3004.0\n",
            "8   70003.0    2480.40  2012-10-10       3003.0\n",
            "9   70012.0     250.45  2012-06-27       3002.0\n",
            "10      NaN      75.29  2012-08-17       3001.0\n",
            "11  70013.0    3045.60  2012-04-25       3001.0\n",
            "\n",
            "Drop the rows where all elements are missing:\n",
            "     ord_no  purch_amt    ord_date  customer_id\n",
            "1       NaN     270.65  2012-09-10       3001.0\n",
            "2   70002.0      65.26         NaN       3001.0\n",
            "3   70004.0     110.50  2012-08-17       3003.0\n",
            "4       NaN     948.50  2012-09-10       3002.0\n",
            "5   70005.0    2400.60  2012-07-27       3001.0\n",
            "6       NaN    5760.00  2012-09-10       3001.0\n",
            "7   70010.0    1983.43  2012-10-10       3004.0\n",
            "8   70003.0    2480.40  2012-10-10       3003.0\n",
            "9   70012.0     250.45  2012-06-27       3002.0\n",
            "10      NaN      75.29  2012-08-17       3001.0\n",
            "11  70013.0    3045.60  2012-04-25       3001.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ques:-8.** Write a Pandas program to keep the rows with at least 2 NaN values in a given DataFrame.\n",
        "\n",
        "**Ans:- result = df.dropna(thresh=2)**\n",
        "\n",
        "**Ques:-9.** Write a Pandas program to drop those rows from a given DataFrame in which specific columns have missing values.\n",
        "\n",
        "**Ans:- result = df.dropna(subset=['ord_no', 'customer_id'])**\n",
        "\n",
        "**Ques:-10.** Write a Pandas program to keep the valid entries of a given DataFrame.\n",
        "\n",
        "**Ans:- result = df.dropna(inplace=False)**----keep only those rows which has no null values\n",
        "\n",
        "**Ques:-11.** Write a Pandas program to calculate the total number of missing values in a DataFrame.\n",
        "\n",
        "**Ans:- result = df.isna().sum().sum()**\n",
        "\n",
        "**Ques:-12.** Write a Pandas program to replace NaNs with a single constant value in specified columns in a DataFrame.\n",
        "\n",
        "**Ans:- result = df['ord_no'].fillna(0, inplace=False)**\n",
        "\n",
        "**Ques:-13.** Write a Pandas program to replace NaNs with the value from the previous row or the next row in a given DataFrame.\n",
        "\n",
        "**Ans:-** Replacing NaNs with the value from the previous row (purch_amt)---**df['purch_amt'].fillna(method='pad', inplace=True)**-----Replacing NaNs with the value from the next row (sale_amt)---**df['sale_amt'].fillna(method='bfill', inplace=True)**\n",
        "\n",
        "**Ques:-14.** Write a Pandas program to replace NaNs with median or mean of the specified columns in a given DataFrame.\n",
        "\n",
        "**Ans:- df['purch_amt'].fillna(df['purch_amt'].median(), inplace=True)---->df['sale_amt'].fillna(int(df['sale_amt'].mean()), inplace=True)**\n",
        "\n",
        "**Ques:-15.** Write a Pandas program to interpolate the missing values using the Linear Interpolation method in a given DataFrame.\n",
        "\n",
        "linear interpolation is a method of curve fitting using linear polynomials to construct new data points within the range of a discrete set of known data points\n",
        "\n",
        "**Ans:- df['purch_amt'].interpolate(method='linear', direction = 'forward', inplace=True)**\n",
        "\n",
        "**Ques:-16.** Write a Pandas program to count the number of missing values of a specified column in a given DataFrame.\n",
        "\n",
        "**Ans:- result = df['purch_amt'].value_counts(dropna=False).loc[np.nan]**\n",
        "\n",
        "**Ques:-18.** Write a Pandas program to find the Indexes of missing values in a given DataFrame.\n",
        "\n",
        "**Ans:- result = df['ord_no'].isnull().to_numpy().nonzero()**\n",
        "\n",
        "**Ques:-19.** Write a Pandas program to replace the missing values with the most frequent values present in each column of a given DataFrame.\n",
        "\n",
        "**Ans:- result = df.fillna(df.mode().iloc[0])**\n",
        "\n",
        "**Ques:-20.** Write a Pandas program to create a hitmap for more information about the distribution of missing values in a given DataFrame.\n",
        "\n",
        "**Ans:-plt.figure(figsize=(16,10))----sns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu\")---plt.show()**"
      ],
      "metadata": {
        "id": "K9cxKNcwX6DX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0s7cTIo7RFeL"
      }
    }
  ]
}